{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Comparisons\n",
    "\n",
    "> Can't rely solely on OpenAI and Azure for WiseGuyAI.com. Need to compare the other LLMs based on cost, performance, and quality.\n",
    "\n",
    "## LLMs\n",
    "\n",
    "1. OpenAI\n",
    "2. Cohere\n",
    "3. A121\n",
    "4. Huggingface Hub\n",
    "5. Azure OpenAI\n",
    "6. Manifest\n",
    "7. Goose Al\n",
    "8. Cerebrium\n",
    "9. Petals\n",
    "10. Forefront AI\n",
    "11. PromptLayer OpenAI\n",
    "12. Anthropic\n",
    "13. Self-Hosted Models (via Runhouse)\n",
    "\n",
    "All LLMs will need to be tested to with the same prompt to see how they compare. We need to keep track of the duration of each request. We also need to try each request at least 3 times to be sure that it gets it correct. \n",
    "\n",
    "We can figure out the prices before we even run most of these models. \n",
    "\n",
    "Gonna use langchain to hopefully make this a little bit easier.\n",
    "\n",
    "Need to sign up for all these services -_-\n",
    "\n",
    "Will track the progress of each by hand in this document + notebooks whenever possible. Honestly maybe this should be a notebook just keep better track.\n",
    "\n",
    "### Define\n",
    "\n",
    "- **Cost**: How much it will cost to run a lot of questions through this model.\n",
    "- **Performance**: How fast it will take to get a response from the model. Latency isn't that important but a slow response is a bad sign that outages could happen.\n",
    "- **Quality**: How good the responses are. This is the most important metric. We need to make sure that the responses are good enough to be used in production."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'langchain[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt loaded. Character count: 4292\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import *\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "import time\n",
    "\n",
    "\n",
    "# open prompt.txt\n",
    "with open('prompt.txt', 'r') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "print(f'Prompt loaded. Character count: {len(prompt)}')\n",
    "\n",
    "# Open keys.json. If it doesnt exist, copy it from example.keys.json\n",
    "try:\n",
    "    with open('keys.json', 'r') as f:\n",
    "        keys = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print('Keys not found. Add your API keys to keys.json')\n",
    "    with open('example.keys.json', 'r') as f:\n",
    "        keys = json.load(f)\n",
    "    with open('keys.json', 'w') as f:\n",
    "        json.dump(keys, f)\n",
    "\n",
    "\n",
    "def ask(llm, price):\n",
    "    start_time = time.time()\n",
    "    results = llm.generate([prompt], stop=['Q: '])\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    first_generation = results.generations[0][0].text\n",
    "    token_usage = results.llm_output['token_usage']\n",
    "    cost = token_usage['total_tokens'] * price\n",
    "    cost = round(cost, 3)\n",
    "\n",
    "    display(Markdown(f\"\"\"### Answer:\\n\\n\n",
    "----- \n",
    "\n",
    "{first_generation}\n",
    "\\n\\n------\n",
    "\n",
    "#### Token usage: {token_usage}\n",
    "\n",
    "#### Cost: ${cost} or ${cost * 1000} per 1000 Questions\n",
    "\n",
    "#### Duration: {duration} seconds\"\"\"))\n",
    "\n",
    "    return {'answer': first_generation, 'token_usage': token_usage, 'cost': cost, 'duration': duration}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This one will be our control. OpenAI is SOTA but they have insane downtime and are the most expensive. \n",
    "\n",
    "#### Pricing\n",
    "\n",
    "- $0.02 per 1,000 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Answer:\n",
       "\n",
       "\n",
       "----- \n",
       "\n",
       " You can use the `deriveAirnodeXpub` function in the [@airnode/airnode-admin](https://github.com/api3dao/airnode/blob/master/packages/airnode-admin/src/implementation.ts#L135) package like this:\n",
       "\n",
       "```js\n",
       "const airnodeXpub = deriveAirnodeXpub(airnodeMnemonic);\n",
       "```\n",
       "\n",
       "\n",
       "------\n",
       "\n",
       "#### Token usage: {'total_tokens': 1536, 'completion_tokens': 92, 'prompt_tokens': 1444}\n",
       "\n",
       "#### Cost: $0.031 or $31.0 per 1000 Questions\n",
       "\n",
       "#### Duration: 4.555056095123291 seconds"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "price = 0.02 / 1000  # 0.02 USD per 1000 tokens\n",
    "\n",
    "# If keys['openai'] falsy, throw error\n",
    "if not keys['openai']:\n",
    "    raise ValueError('OpenAI API key not found. Add your API key to keys.json')\n",
    "\n",
    "\n",
    "openai = OpenAI(model_name=\"text-davinci-003\", openai_api_key=keys['openai'])\n",
    "\n",
    "openai_results = ask(openai, price)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "| Cost | Performance | Quality |\n",
    "|------|-------------|---------|\n",
    "| 1  |     2      |    5   |\n",
    "\n",
    "At $0.03 per question, this will probably be our most expensive model. Average response time was around 5 seconds. I know from experience they have a lot of downtime. The answer quality is amazing. Exactly what I am looking for. Truly SOTA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb2c640052a679058fa963edb19c73c9244639affc4049c356a2be62de116d7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
