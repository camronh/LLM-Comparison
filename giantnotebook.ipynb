{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Comparisons\n",
    "\n",
    "> Can't rely solely on OpenAI and Azure for WiseGuyAI.com. Need to compare the other LLMs based on price, performance, and quality.\n",
    "\n",
    "## LLMs\n",
    "\n",
    "1. OpenAI\n",
    "2. Cohere\n",
    "3. A121\n",
    "4. Huggingface Hub\n",
    "5. Azure OpenAI\n",
    "6. Manifest\n",
    "7. Goose Al\n",
    "8. Cerebrium\n",
    "9. Petals\n",
    "10. Forefront AI\n",
    "11. PromptLayer OpenAI\n",
    "12. Anthropic\n",
    "13. Self-Hosted Models (via Runhouse)\n",
    "\n",
    "## Idk\n",
    "\n",
    "All LLMs will need to be tested to with the same prompt to see how they compare. We need to keep track of the duration of each request. We also need to try each request at least 3 times to be sure that it gets it correct. \n",
    "\n",
    "We can figure out the prices before we even run most of these models. \n",
    "\n",
    "Gonna use langchain to hopefully make this a little bit easier.\n",
    "\n",
    "Need to sign up for all these services -_-\n",
    "\n",
    "Will track the progress of each by hand in this document + notebooks whenever possible. Honestly maybe this should be a notebook just keep better track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'langchain[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt loaded. Character count: 4292\n",
      "Keys loaded.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import *\n",
    "import json\n",
    "\n",
    "# open prompt.txt\n",
    "with open('prompt.txt', 'r') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "print(f'Prompt loaded. Character count: {len(prompt)}')\n",
    "\n",
    "# Open keys.json. If it doesnt exist, copy it from example.keys.json\n",
    "try:\n",
    "    with open('keys.json', 'r') as f:\n",
    "        keys = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print('Keys not found. Add your API keys to keys.json')\n",
    "    with open('example.keys.json', 'r') as f:\n",
    "        keys = json.load(f)\n",
    "    with open('keys.json', 'w') as f:\n",
    "        json.dump(keys, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "This one will be our control. OpenAI is SOTA but they have insane downtime and are the most expensive. Lets take down some notes.\n",
    "\n",
    "#### Pricing\n",
    "\n",
    "- $0.02 per 1,000 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "366460805f9ae0631148fe9a7b032f73bb4718aebbfc9bc58643533ccf221da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
